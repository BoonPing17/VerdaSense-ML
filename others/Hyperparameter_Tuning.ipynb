{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmwG38XaR86A"
      },
      "source": [
        "# **Hyperparameter Tuning notebook**\n",
        "- This notebook is to tune the parameters of DeepLabV3+ with MobileNetV2 backbone\n",
        "- Utilize Weight and Biases Sweep for hyperparamter tuning\n",
        "- The hyperparameters that are going to be tuned are `learning_rate`, `batch_size`, `threshold`, `bce_weights`, `augmentation_probability`, and `optimizer`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBqz2VbJK5sT"
      },
      "source": [
        "## **Import**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzmpbNPKK3RE",
        "outputId": "7ee104f4-9787-4bde-8dfa-1b171e69fefc"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Q_ewT-iLOMD",
        "outputId": "c3f057b5-388b-4c7c-f1bd-a2d5dedbdbc8"
      },
      "outputs": [],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXZuf18ECGsl",
        "outputId": "816ad00c-11cd-4b38-ff77-344510441caf"
      },
      "outputs": [],
      "source": [
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duC-hmdvGa3w"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import wandb\n",
        "from torchinfo import summary\n",
        "from torchvision import models\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GatdfQH-M3-3"
      },
      "outputs": [],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juOUpPIfW1F1"
      },
      "source": [
        "### Move data to local disk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zd85_nXcw3_P"
      },
      "source": [
        "**Note:** Replace your own paths here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvp_n3OPW4O3",
        "outputId": "a9d14981-43d9-46b0-e3a5-d99dee76d88c"
      },
      "outputs": [],
      "source": [
        "zip_train_source_path = \"/content/drive/MyDrive/FYP/Datasets/zipped/train.zip\"\n",
        "zip_val_source_path = \"/content/drive/MyDrive/FYP/Datasets/zipped/validation.zip\"\n",
        "\n",
        "local_data_dir = \"/content/data\"\n",
        "\n",
        "!mkdir -p \"$local_data_dir\"\n",
        "\n",
        "print(f\"Copying {zip_train_source_path} to {local_data_dir}\")\n",
        "!cp \"$zip_train_source_path\" \"$local_data_dir/\"\n",
        "\n",
        "print(f\"Copying {zip_val_source_path} to {local_data_dir}\")\n",
        "!cp \"$zip_val_source_path\" \"$local_data_dir/\"\n",
        "\n",
        "print(\"Copying complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gO7DL7lRkqS-",
        "outputId": "46446884-df2b-421d-bb69-551249b361d0"
      },
      "outputs": [],
      "source": [
        "local_zip_train_path = f\"{local_data_dir}/train.zip\"\n",
        "local_zip_val_path = f\"{local_data_dir}/validation.zip\"\n",
        "\n",
        "unzip_destination_path = local_data_dir\n",
        "\n",
        "print(f\"Unzipping {local_zip_train_path} to {unzip_destination_path}\")\n",
        "!unzip -q \"$local_zip_train_path\" -d \"$unzip_destination_path\"\n",
        "\n",
        "print(f\"Unzipping {local_zip_val_path} to {unzip_destination_path}\")\n",
        "!unzip -q \"$local_zip_val_path\" -d \"$unzip_destination_path\"\n",
        "\n",
        "print(\"Unzipping complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIHpT75-lXWV",
        "outputId": "eb698768-213f-4893-d7bd-c1bf877eea08"
      },
      "outputs": [],
      "source": [
        "local_train_image_path = os.path.join(local_data_dir, \"train\", \"images\")\n",
        "local_train_mask_path = os.path.join(local_data_dir, \"train\", \"masks\")\n",
        "\n",
        "# Check if directories exist\n",
        "if os.path.exists(local_train_image_path):\n",
        "  num_images = len(os.listdir(local_train_image_path))\n",
        "  print(f\"Number of images in {local_train_image_path}: {num_images}\")\n",
        "else:\n",
        "  print(f\"Directory {local_train_image_path} does not exist.\")\n",
        "\n",
        "if os.path.exists(local_train_mask_path):\n",
        "  num_masks = len(os.listdir(local_train_mask_path))\n",
        "  print(f\"Number of masks in {local_train_mask_path}: {num_masks}\")\n",
        "else:\n",
        "  print(f\"Directory {local_train_mask_path} does not exist.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq1xmWL5mDmZ",
        "outputId": "ffd3fd60-477b-4b2c-e29e-7936cc85c83a"
      },
      "outputs": [],
      "source": [
        "local_val_image_path = os.path.join(local_data_dir, \"validation\", \"images\")\n",
        "local_val_mask_path = os.path.join(local_data_dir, \"validation\", \"masks\")\n",
        "\n",
        "# Check if directories exist\n",
        "if os.path.exists(local_val_image_path):\n",
        "  num_images = len(os.listdir(local_val_image_path))\n",
        "  print(f\"Number of images in {local_val_image_path}: {num_images}\")\n",
        "else:\n",
        "  print(f\"Directory {local_val_image_path} does not exist.\")\n",
        "\n",
        "if os.path.exists(local_val_mask_path):\n",
        "  num_masks = len(os.listdir(local_val_mask_path))\n",
        "  print(f\"Number of masks in {local_val_mask_path}: {num_masks}\")\n",
        "else:\n",
        "  print(f\"Directory {local_val_mask_path} does not exist.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbb1d41VkrUZ"
      },
      "outputs": [],
      "source": [
        "!rm \"$local_zip_train_path\"\n",
        "!rm \"$local_zip_val_path\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiWR2wkNT5zF"
      },
      "source": [
        "## **Defining the sweep**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yb2WqO6dT-Gw"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    'method': 'bayes'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zE68KGOOnBl_"
      },
      "outputs": [],
      "source": [
        "metric = {\n",
        "    'name': 'val_iou',\n",
        "    'goal': 'maximize',\n",
        "}\n",
        "\n",
        "sweep_config['metric'] = metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaCt73YfnL1m"
      },
      "outputs": [],
      "source": [
        "parameters_dict = {\n",
        "    'epochs' : {\n",
        "      'value': 5\n",
        "    },\n",
        "    'optimizer': {\n",
        "        'value': 'adam'\n",
        "    },\n",
        "    'batch_size': {\n",
        "        'value': 64\n",
        "    },\n",
        "    'learning_rate': {\n",
        "        'distribution': 'log_uniform_values',\n",
        "        'min': 0.0001,\n",
        "        'max': 0.01,\n",
        "    },\n",
        "    'threshold': {\n",
        "        'distribution': 'uniform',\n",
        "        'min': 0.40,\n",
        "        'max': 0.60,\n",
        "    },\n",
        "    'bce_weight': {\n",
        "        'distribution': 'uniform',\n",
        "        'min': 0.5,\n",
        "        'max': 0.6,\n",
        "    },\n",
        "    'augmentation_p': {\n",
        "      'distribution': 'uniform',\n",
        "      'min': 0.6,\n",
        "      'max': 0.8,\n",
        "    },\n",
        "}\n",
        "\n",
        "sweep_config['parameters'] = parameters_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-PSnNsVnl-U",
        "outputId": "e9c1447f-93d0-4423-eca4-a463e1540a92"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "pprint.pprint(sweep_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80lxBFwZK7RV"
      },
      "source": [
        "## **Relevant code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgGfP83cLEqa"
      },
      "source": [
        "### Custom SegmentationDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BnrS186Vt5m"
      },
      "outputs": [],
      "source": [
        "dataset_mean = (0.55943902, 0.50729719, 0.48297841)\n",
        "dataset_std = (0.25904843, 0.25247732, 0.25680549)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvF0JAL2G3tC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import albumentations as A\n",
        "\n",
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, transform=None, img_size=(224, 224), mean=dataset_mean, std=dataset_std):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transform # Only for geometric transformations\n",
        "        self.images = sorted(os.listdir(image_dir))\n",
        "        self.masks = sorted(os.listdir(mask_dir))\n",
        "        self.img_size = img_size\n",
        "        self.mean = np.array(mean)\n",
        "        self.std = np.array(std)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.images[idx]\n",
        "        mask_name = self.masks[idx]\n",
        "\n",
        "        image_path = os.path.join(self.image_dir, img_name)\n",
        "        mask_path = os.path.join(self.mask_dir, mask_name)\n",
        "\n",
        "        # Albumentations expects a NumPy array with uint8 data type\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Apply the geometric transformations\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image, mask=mask)\n",
        "            image = augmented['image']\n",
        "            mask = augmented['mask']\n",
        "\n",
        "        # Manual steps for resize, standardization, and conversion\n",
        "        # 1. Resize if necessary\n",
        "        if image.shape[0] != self.img_size[0] or image.shape[1] != self.img_size[1]:\n",
        "            image = cv2.resize(image, self.img_size)\n",
        "        if mask.shape[0] != self.img_size[0] or mask.shape[1] != self.img_size[1]:\n",
        "            mask = cv2.resize(mask, self.img_size, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        # 2. Convert image to float and standardize\n",
        "        image = image.astype(\"float32\") / 255.0\n",
        "        image = (image - self.mean) / self.std\n",
        "\n",
        "        # 3. Convert image to torch tensor and permute (HWC -> CHW)\n",
        "        image = torch.from_numpy(image).permute(2, 0, 1)\n",
        "\n",
        "        # 4. Convert mask to float and add a channel dimension\n",
        "        mask = (mask > 0).astype(\"float32\") # Convert to binary (0.0 or 1.0)\n",
        "        mask = torch.from_numpy(mask).unsqueeze(0) # HW -> 1HW\n",
        "\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhMkuwslKqiy"
      },
      "source": [
        "### Function to get the datasets and dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYq_36YZHk6P"
      },
      "outputs": [],
      "source": [
        "def get_datasets_dataloaders(augmentation_probability, batch_size):\n",
        "  \"\"\"\n",
        "  Sets up and returns the DataLoader objects with configurable hyperparameters.\n",
        "\n",
        "  Args:\n",
        "    augmentation_probability (float): The probability 'p' for data augmentations.\n",
        "    batch_size (int): The number of samples per batch.\n",
        "\n",
        "  Returns:\n",
        "    tuple: A tuple containing the train_loader and val_loader\n",
        "  \"\"\"\n",
        "\n",
        "  # Data augmentation setup\n",
        "  train_transform = A.Compose([\n",
        "      A.HorizontalFlip(p=augmentation_probability),\n",
        "      A.VerticalFlip(p=augmentation_probability),\n",
        "      A.RandomRotate90(p=augmentation_probability),\n",
        "      A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.3),\n",
        "      A.GaussNoise(p=augmentation_probability),\n",
        "      A.GridDistortion(num_steps=5, distort_limit=0.3, p=augmentation_probability),\n",
        "      A.ElasticTransform(alpha=1, sigma=50, p=augmentation_probability),\n",
        "      A.CoarseDropout(p=augmentation_probability),\n",
        "  ])\n",
        "\n",
        "  original_train_image_path = local_train_image_path\n",
        "  original_train_label_path = local_train_mask_path\n",
        "  original_val_image_path = local_val_image_path\n",
        "  original_val_label_path = local_val_mask_path\n",
        "\n",
        "  # Create the datasets and data loaders using the on-the-fly transformations.\n",
        "  train_dataset = SegmentationDataset(original_train_image_path, original_train_label_path, transform=train_transform)\n",
        "  val_dataset = SegmentationDataset(original_val_image_path, original_val_label_path)\n",
        "\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "  val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "  return train_dataset, train_loader, val_dataset, val_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFeyXeXqLxQV"
      },
      "source": [
        "### DeepLabv3+ with MobileNetV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyHNZNOLLz-0"
      },
      "outputs": [],
      "source": [
        "class SeparableConv2d(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements Depthwise Separable Convolution, which is a depthwise convolution\n",
        "    followed by a pointwise (1x1) convolution.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, dilation=1):\n",
        "        super(SeparableConv2d, self).__init__()\n",
        "\n",
        "        # Depthwise convolution: Applies a separate filter to each input channel\n",
        "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size, stride, padding, dilation, groups=in_channels, bias=False)\n",
        "        self.bn_depth = nn.BatchNorm2d(in_channels)\n",
        "        self.relu_depth = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Pointwise convolution: A 1x1 convolution to mix the channels\n",
        "        self.pointwise = nn.Conv2d(in_channels, out_channels, 1, stride=1, padding=0, bias=False)\n",
        "        self.bn_point = nn.BatchNorm2d(out_channels)\n",
        "        self.relu_point = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.depthwise(x)\n",
        "        x = self.bn_depth(x)\n",
        "        x = self.relu_depth(x)\n",
        "\n",
        "        x = self.pointwise(x)\n",
        "        x = self.bn_point(x)\n",
        "        x = self.relu_point(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxy1eMRgL3ci"
      },
      "outputs": [],
      "source": [
        "class ASPP(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ASPP, self).__init__()\n",
        "\n",
        "        # 1x1 convolution branch (This is always a standard 1x1 convolution)\n",
        "        self.conv1x1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Atrous separable convolution with rate=6\n",
        "        self.atrous_block6 = SeparableConv2d(in_channels, out_channels, kernel_size=3, padding=12, dilation=12)\n",
        "\n",
        "        # Atrous separable convolution with rate=12\n",
        "        self.atrous_block12 = SeparableConv2d(in_channels, out_channels, kernel_size=3, padding=24, dilation=24)\n",
        "\n",
        "        # Atrous separable convolution with rate=18\n",
        "        self.atrous_block18 = SeparableConv2d(in_channels, out_channels, kernel_size=3, padding=36, dilation=36)\n",
        "\n",
        "        # Global Average Pooling branch\n",
        "        self.global_avg_pool = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Conv2d(in_channels, out_channels, 1, stride=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Final 1x1 convolution to fuse all 5 branches\n",
        "        self.final_conv = nn.Sequential(\n",
        "            nn.Conv2d(out_channels * 5, out_channels, kernel_size=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        size = x.size()[2:]\n",
        "\n",
        "        x1 = self.conv1x1(x)\n",
        "        x2 = self.atrous_block6(x)\n",
        "        x3 = self.atrous_block12(x)\n",
        "        x4 = self.atrous_block18(x)\n",
        "        x5 = self.global_avg_pool(x)\n",
        "\n",
        "        x5 = F.interpolate(x5, size=size, mode='bilinear', align_corners=False)\n",
        "\n",
        "        x = torch.cat((x1, x2, x3, x4, x5), dim=1)\n",
        "\n",
        "        x = self.final_conv(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_S585RzL6Uf"
      },
      "outputs": [],
      "source": [
        "class DeepLabV3Plus(nn.Module):\n",
        "    def __init__(self, num_classes=1):\n",
        "        super(DeepLabV3Plus, self).__init__()\n",
        "        backbone = models.mobilenet_v2(pretrained=True)\n",
        "        self.backbone = backbone.features  # Get all layers except classifier\n",
        "\n",
        "        # Using stride of 16\n",
        "        self.backbone[14].conv[1][0].stride = (1, 1)\n",
        "\n",
        "        # Low-level features come from early layer (for decoder)\n",
        "        self.low_level_idx = 3\n",
        "        self.low_level_channels = 24\n",
        "\n",
        "        # ASPP expects 1280 channels from the last MobileNetV2 layer\n",
        "        self.aspp = ASPP(in_channels=1280, out_channels=256)\n",
        "\n",
        "        # Decoder\n",
        "        self.low_level_project = nn.Sequential(\n",
        "            nn.Conv2d(self.low_level_channels, 48, kernel_size=1),\n",
        "            nn.BatchNorm2d(48),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Conv2d(256 + 48, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, num_classes, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "      input_size = x.size()[2:]\n",
        "\n",
        "      # Extract low-level and high-level features\n",
        "      low_level_feat = None\n",
        "      feat = x\n",
        "      for i, layer in enumerate(self.backbone):\n",
        "          feat = layer(feat)\n",
        "          if i == self.low_level_idx:\n",
        "              low_level_feat = feat  # Save for decoder\n",
        "\n",
        "      high_level_feat = feat  # Final output of backbone (usually [B, 1280, H/32, W/32])\n",
        "\n",
        "      # ASPP on high-level features\n",
        "      x = self.aspp(high_level_feat)\n",
        "      x = F.interpolate(x, size=low_level_feat.shape[2:], mode='bilinear', align_corners=False)\n",
        "\n",
        "      # Decoder\n",
        "      low_level = self.low_level_project(low_level_feat)\n",
        "      x = torch.cat([x, low_level], dim=1)\n",
        "      x = self.decoder(x)\n",
        "      x = F.interpolate(x, size=input_size, mode='bilinear', align_corners=False)\n",
        "      return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quKBHtAvMCtN"
      },
      "source": [
        "### Function to initialize and get the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpGRSXyiMljW"
      },
      "outputs": [],
      "source": [
        "def get_model():\n",
        "  model = DeepLabV3Plus(num_classes=1)\n",
        "  return model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKL1cN85S9Mb"
      },
      "source": [
        "### Criterion class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnnWHi3vMKCA"
      },
      "outputs": [],
      "source": [
        "class DiceBCELoss(nn.Module):\n",
        "    def __init__(self, bce_weight=0.6, size_average=True):\n",
        "        super(DiceBCELoss, self).__init__()\n",
        "        self.bce_loss = nn.BCEWithLogitsLoss(reduction='mean')\n",
        "        self.bce_weight = bce_weight\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1):\n",
        "        # Apply sigmoid to convert logits to probabilities\n",
        "        inputs_sig = torch.sigmoid(inputs)\n",
        "\n",
        "        # Flatten label and prediction tensors for Dice Loss\n",
        "        inputs_flat = inputs_sig.view(-1)\n",
        "        targets_flat = targets.view(-1)\n",
        "\n",
        "        # Calculate Dice Loss\n",
        "        intersection = (inputs_flat * targets_flat).sum()\n",
        "        dice_loss = 1 - (2. * intersection + smooth) / (inputs_flat.sum() + targets_flat.sum() + smooth)\n",
        "\n",
        "        # Calculate BCE Loss on original logits\n",
        "        bce_loss_val = self.bce_loss(inputs, targets)\n",
        "\n",
        "        # Combine the two losses\n",
        "        combined_loss = self.bce_weight * bce_loss_val + (1 - self.bce_weight) * dice_loss\n",
        "\n",
        "        return combined_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUZgMGJ3TKqT"
      },
      "source": [
        "### Functions to calculate the metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBV6Gx5DC2SC"
      },
      "outputs": [],
      "source": [
        "def get_confusion_matrix_components(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculates the confusion matrix components (TP, FP, FN) for a batch.\n",
        "\n",
        "    Args:\n",
        "        y_true (torch.Tensor): Ground truth masks, a tensor of 0s and 1s.\n",
        "        y_pred (torch.Tensor): Binary tensor after applying the sigmoid function and threshold.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing True Positives, False Positives, False Negatives, and True Negatives.\n",
        "    \"\"\"\n",
        "\n",
        "    # Flatten tensors for easier calculation\n",
        "    y_true_flat = y_true.view(-1)\n",
        "    y_pred_flat = y_pred.view(-1)\n",
        "\n",
        "    # Calculate confusion matrix components\n",
        "    true_positives = ((y_pred_flat == 1) & (y_true_flat == 1)).sum().item()\n",
        "    false_positives = ((y_pred_flat == 1) & (y_true_flat == 0)).sum().item()\n",
        "    false_negatives = ((y_pred_flat == 0) & (y_true_flat == 1)).sum().item()\n",
        "    true_negatives = ((y_pred_flat == 0) & (y_true_flat == 0)).sum().item()\n",
        "\n",
        "    return true_positives, false_positives, false_negatives, true_negatives\n",
        "\n",
        "\n",
        "def calculate_final_metrics(tp, fp, fn, tn, smooth=1e-6):\n",
        "    \"\"\"\n",
        "    Calculates final metrics from accumulated confusion matrix components.\n",
        "    \"\"\"\n",
        "    # IoU\n",
        "    intersection = tp\n",
        "    union = tp + fp + fn\n",
        "    iou = intersection / (union + smooth)\n",
        "\n",
        "    # Recall (Sensitivity)\n",
        "    recall = tp / (tp + fn + smooth)\n",
        "\n",
        "    # Precision (Positive Predictive Value)\n",
        "    precision = tp / (tp + fp + smooth)\n",
        "\n",
        "    # Dice Coefficient / F1\n",
        "    dice = (2 * precision * recall) / (precision + recall + smooth)\n",
        "\n",
        "    # Accuracy\n",
        "    accuracy = (tp + tn) / (tp + tn + fp + fn + smooth)\n",
        "\n",
        "    return iou, dice, recall, precision, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QfTfCDLTOXd"
      },
      "source": [
        "### Function to get the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxjvF9sOLapF"
      },
      "outputs": [],
      "source": [
        "def get_optimizer(model, optimizer, learning_rate):\n",
        "  if optimizer == \"sgd\":\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr= learning_rate, momentum=0.9)\n",
        "  elif optimizer == \"adam\":\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "  return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21dfw7A9TR49"
      },
      "source": [
        "### Function to train and validate the model for one epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGUg1vGzNGur"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, train_dataset, train_loader, val_dataset, val_loader, criterion, optimizer, threshold, device):\n",
        "  # --- Training Phase ---\n",
        "  model.train()\n",
        "  train_running_loss = 0.0\n",
        "  train_total_tp, train_total_fp, train_total_fn, train_total_tn = 0, 0, 0, 0\n",
        "\n",
        "  for X_batch, y_batch in train_loader:\n",
        "    X_batch, y_batch = X_batch.to(device).float(), y_batch.to(device).float()\n",
        "    output = model(X_batch)\n",
        "\n",
        "    # BCEwithLogitsLoss expects raw output (the logits)\n",
        "    loss = criterion(output, y_batch)\n",
        "\n",
        "    # Accumulate the loss (loss * batch_size)\n",
        "    train_running_loss += loss.item() * X_batch.size(0)\n",
        "\n",
        "    optimizer.zero_grad() # clear the gradients\n",
        "    loss.backward() # Backward pass\n",
        "    optimizer.step() # Update weights\n",
        "\n",
        "    # Convert to binary predictions (either 0 or 1)\n",
        "    train_probs = torch.sigmoid(output)\n",
        "    train_preds = (train_probs > threshold).float()\n",
        "\n",
        "    # Accumulate confusion matrix components\n",
        "    tp, fp, fn, tn = get_confusion_matrix_components(y_batch, train_preds)\n",
        "    train_total_tp += tp\n",
        "    train_total_fp += fp\n",
        "    train_total_fn += fn\n",
        "    train_total_tn += tn\n",
        "\n",
        "  # Calculate final epoch metrics\n",
        "  train_loss = train_running_loss / len(train_dataset)\n",
        "  train_iou, train_dice, train_recall, train_precision, train_acc = calculate_final_metrics(train_total_tp, train_total_fp, train_total_fn, train_total_tn)\n",
        "\n",
        "  # --- Validation Phase ---\n",
        "  model.eval()\n",
        "\n",
        "  # Initialize validation loss and confusion matrix components\n",
        "  val_running_loss = 0.0\n",
        "  val_total_tp, val_total_fp, val_total_fn, val_total_tn = 0, 0, 0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X_val_batch, y_val_batch in val_loader:\n",
        "      X_val_batch, y_val_batch = X_val_batch.to(device).float(), y_val_batch.to(device).float()\n",
        "      val_output = model(X_val_batch)\n",
        "\n",
        "      # Get the validation loss\n",
        "      val_loss = criterion(val_output, y_val_batch)\n",
        "      val_running_loss += val_loss.item() * X_val_batch.size(0)\n",
        "\n",
        "      # Convert to binary tensors\n",
        "      val_probs = torch.sigmoid(val_output)\n",
        "      val_preds = (val_probs > threshold).float()\n",
        "\n",
        "      tp, fp, fn, tn = get_confusion_matrix_components(y_val_batch, val_preds)\n",
        "      val_total_tp += tp\n",
        "      val_total_fp += fp\n",
        "      val_total_fn += fn\n",
        "      val_total_tn += tn\n",
        "\n",
        "  val_loss = val_running_loss / len(val_dataset)\n",
        "  val_iou, val_dice, val_recall, val_precision, val_acc = calculate_final_metrics(val_total_tp, val_total_fp, val_total_fn, val_total_tn)\n",
        "\n",
        "  return train_loss, train_iou, train_dice, val_loss, val_iou, val_dice\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z4k0G10Rl8Y"
      },
      "source": [
        "### Getting the device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxW5GmALMCL5",
        "outputId": "78c3c43a-830f-4213-8f8c-22d19fb45eb8"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL7JEPqeTb90"
      },
      "source": [
        "### training logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xMnXG5oL83t"
      },
      "outputs": [],
      "source": [
        "def train(config=None):\n",
        "\n",
        "  # Initialize a new wandb run\n",
        "  with wandb.init(config=config):\n",
        "\n",
        "    # this config will be set by Sweep Controller\n",
        "    config = wandb.config\n",
        "\n",
        "    train_dataset, train_loader, val_dataset, val_loader = get_datasets_dataloaders(config.augmentation_p, config.batch_size)\n",
        "    model = get_model()\n",
        "    criterion = DiceBCELoss(config.bce_weight)\n",
        "    optimizer = get_optimizer(model, config.optimizer, config.learning_rate)\n",
        "\n",
        "    for epoch in range(config.epochs + 1):\n",
        "      train_loss, train_iou, train_dice, val_loss, val_iou, val_dice = train_epoch(model, train_dataset, train_loader, val_dataset, val_loader, criterion, optimizer, config.threshold, device)\n",
        "\n",
        "      # Log all metrics to W&B\n",
        "      wandb.log({\n",
        "        \"epoch\": epoch,\n",
        "        \"train_loss\": train_loss,\n",
        "        \"train_iou\": train_iou,\n",
        "        \"train_dice\": train_dice,\n",
        "        \"val_loss\": val_loss,\n",
        "        \"val_iou\": val_iou,\n",
        "        \"val_dice\": val_dice,\n",
        "    })\n",
        "\n",
        "    print(\"Training for 5 epochs has completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qih0X6fkMdxE"
      },
      "source": [
        "## **Initialize Sweep**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK0MjqdmR2G0",
        "outputId": "9d03b3e8-6c80-4885-de72-abaced629b56"
      },
      "outputs": [],
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=\"DeepLabv3+_Sweeps\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZVV9wKLR2o-"
      },
      "source": [
        "## **Activate Sweep Agents**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E5Ay4LbYR505",
        "outputId": "f9045fbc-550e-48bc-8436-8f803ed125f5"
      },
      "outputs": [],
      "source": [
        "wandb.agent(sweep_id, train, count=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9XTXEBriOnj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
